{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepneuralnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KEY_LAYER_DIMS': [10, 2], 'KEY_LEARNING_RATE': 0.001, 'KEY_DROPOUT_KEEP_PROB': 0.8, 'KEY_MAX_NORM_CLIP': 3.0, 'KEY_ADAM_BETA1': 0.97, 'KEY_MINI_BATCH_SIZE': 64}\n"
     ]
    }
   ],
   "source": [
    "# Set up hyper parameters \n",
    "classes = 2\n",
    "layer_dims = [10, classes] \n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.8\n",
    "minibatch_size = 64\n",
    "momentum = 0.97\n",
    "maxnorm_clip = 3\n",
    "print_summary = False\n",
    "isBinary = classes == 2 \n",
    "hyperparams = DNN.create_hyperparameter_bundle(layer_dims=layer_dims, \n",
    "                                               learning_rate=learning_rate, \n",
    "                                               dropout_keep_prob = keep_prob, \n",
    "                                               dropout_maxnorm_clip = maxnorm_clip, \n",
    "                                               beta1 = momentum, \n",
    "                                               minibatch_size = minibatch_size)\n",
    "print(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "m = 1000\n",
    "n_x = 100\n",
    "label = 'Survived'\n",
    "x_data = np.random.rand(m, n_x).astype('float32')\n",
    "y_test = None\n",
    "\n",
    "if isBinary:\n",
    "    y_test = np.random.randint(2, size=(1, m)).astype('float32')[0]\n",
    "else:\n",
    "    y_test = np.random.randint(classes, size=(1, m)).astype('float32')[0]\n",
    "\n",
    "df = pd.DataFrame(x_data)\n",
    "df[label] = y_test\n",
    "classification = len(set(y_test))\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting hyperparameters...\n",
      "train_x.shape: (700, 100)\n",
      "train_y.shape: (700, 2)\n",
      "dev_x.shape: (300, 100)\n",
      "dev_y.shape: (300, 2)\n",
      "Configuring graph...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DNN' object has no attribute '_DNN__tf_batch_norm_pop_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d69aa368a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m results = nn.train(train_x, train_y, dev_x, dev_y, \n\u001b[1;32m      7\u001b[0m                    \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sfung/github/DeepNeuralNet/deepneuralnet.py\u001b[0m in \u001b[0;36mconfigure_graph\u001b[0;34m(self, train_x, train_y)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_Y_place\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__initialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_Z_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__forward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_cost_func\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_Z_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_Y_place\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_learningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_adam_beta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_cost_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sfung/github/DeepNeuralNet/deepneuralnet.py\u001b[0m in \u001b[0;36m__forward_propagation\u001b[0;34m(self, isTraining)\u001b[0m\n\u001b[1;32m    584\u001b[0m                 \u001b[0mbatch_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 train_mean = tf.assign(self.__tf_batch_norm_pop_mean,\n\u001b[0m\u001b[1;32m    587\u001b[0m                                        self.__tf_batch_norm_pop_mean * decay + batch_mean * (1 - decay))\n\u001b[1;32m    588\u001b[0m                 train_var = tf.assign(self.__tf_batch_norm_pop_var,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DNN' object has no attribute '_DNN__tf_batch_norm_pop_mean'"
     ]
    }
   ],
   "source": [
    "# Typical DNN use case\n",
    "nn = DNN()\n",
    "nn.set_hyperparameters(hyperparams)\n",
    "(train_x, train_y, dev_x, dev_y) = DNN.split_data(df, label, 0.7)\n",
    "nn.configure_graph(train_x, train_y)\n",
    "results = nn.train(train_x, train_y, dev_x, dev_y, \n",
    "                   num_epochs = 250, print_summary = True, \n",
    "                   checkpoint_interval = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = nn.predict(x_data)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring saved model from cell above\n",
    "dnn2 = DNN()\n",
    "dnn2.restore_saved_model(1, 200)\n",
    "results2 = dnn2.train(train_x, train_y, dev_x, dev_y, \n",
    "                      num_epochs = 250, print_summary = True, \n",
    "                      checkpoint_interval = 200)\n",
    "predictions2 = dnn2.predict(x_data)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using convenience methods\n",
    "nn3 = DNN(identifier=2)\n",
    "nn3.set_hyperparams_split_data_configure_train(hyperparams, \n",
    "                                               df, \n",
    "                                               label, \n",
    "                                               num_epochs = 100, \n",
    "                                               split_percent = 0.7, \n",
    "                                               print_summary = True, \n",
    "                                               checkpoint_interval = 50)\n",
    "predictions3 = nn3.predict(x_data)\n",
    "print(predictions3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
