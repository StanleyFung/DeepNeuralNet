{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepneuralnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KEY_LAYER_DIMS': [10, 2], 'KEY_LEARNING_RATE': 0.001, 'KEY_DROPOUT_KEEP_PROB': 0.8, 'KEY_MAX_NORM_CLIP': 3.0, 'KEY_ADAM_BETA1': 0.97, 'KEY_MINI_BATCH_SIZE': 64}\n"
     ]
    }
   ],
   "source": [
    "# Set up hyper parameters \n",
    "classes = 2\n",
    "layer_dims = [10, classes] \n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.8\n",
    "minibatch_size = 64\n",
    "momentum = 0.97\n",
    "maxnorm_clip = 3\n",
    "print_summary = False\n",
    "isBinary = classes == 2 \n",
    "hyperparams = DNN.create_hyperparameter_bundle(layer_dims=layer_dims, \n",
    "                                               learning_rate=learning_rate, \n",
    "                                               dropout_keep_prob = keep_prob, \n",
    "                                               dropout_maxnorm_clip = maxnorm_clip, \n",
    "                                               beta1 = momentum, \n",
    "                                               minibatch_size = minibatch_size)\n",
    "print(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "m = 1000\n",
    "n_x = 100\n",
    "label = 'Survived'\n",
    "x_data = np.random.rand(m, n_x).astype('float32')\n",
    "y_test = None\n",
    "\n",
    "if isBinary:\n",
    "    y_test = np.random.randint(2, size=(1, m)).astype('float32')[0]\n",
    "else:\n",
    "    y_test = np.random.randint(classes, size=(1, m)).astype('float32')[0]\n",
    "\n",
    "df = pd.DataFrame(x_data)\n",
    "df[label] = y_test\n",
    "classification = len(set(y_test))\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting hyperparameters...\n",
      "train_x.shape: (700, 100)\n",
      "train_y.shape: (700, 2)\n",
      "dev_x.shape: (300, 100)\n",
      "dev_y.shape: (300, 2)\n",
      "Configuring graph...\n"
     ]
    }
   ],
   "source": [
    "# Typical DNN use case\n",
    "nn = DNN()\n",
    "nn.set_hyperparameters(hyperparams)\n",
    "(train_x, train_y, dev_x, dev_y) = DNN.split_data(df, label, 0.7)\n",
    "nn.configure_graph(train_x, train_y)\n",
    "results = nn.train(train_x, train_y, dev_x, dev_y, \n",
    "                   num_epochs = 250, print_summary = True, \n",
    "                   checkpoint_interval = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = nn.predict(x_data)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring saved model from cell above\n",
    "dnn2 = DNN()\n",
    "dnn2.restore_saved_model(1, 200)\n",
    "results2 = dnn2.train(train_x, train_y, dev_x, dev_y, \n",
    "                      num_epochs = 250, print_summary = True, \n",
    "                      checkpoint_interval = 200)\n",
    "predictions2 = dnn2.predict(x_data)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using convenience methods\n",
    "nn3 = DNN(identifier=2)\n",
    "nn3.set_hyperparams_split_data_configure_train(hyperparams, \n",
    "                                               df, \n",
    "                                               label, \n",
    "                                               num_epochs = 100, \n",
    "                                               split_percent = 0.7, \n",
    "                                               print_summary = True, \n",
    "                                               checkpoint_interval = 50)\n",
    "predictions3 = nn3.predict(x_data)\n",
    "print(predictions3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
